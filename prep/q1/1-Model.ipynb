{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcab801c",
   "metadata": {},
   "source": [
    "### Loading Train Set from File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac7f2a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.sparse import load_npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "638706dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_texts.pkl', 'rb') as f:\n",
    "    train_texts = pickle.load(f)\n",
    "    \n",
    "train_cat = load_npz('train_cat.npz')\n",
    "\n",
    "with open('train_label.npy', 'rb') as f:\n",
    "    train_label = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e5fd866",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_label = np.max(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8810457c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_label = 62852500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a193ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train_label / max_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ae008c",
   "metadata": {},
   "source": [
    "### Train-Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f1fa8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "426971f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cat = train_cat.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee89646e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4c94730",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = len(train_texts)\n",
    "indices = np.arange(train_len)\n",
    "np.random.shuffle(indices, )\n",
    "train_idx = indices[:math.floor(0.9*train_len)]\n",
    "val_idx = indices[math.floor(0.9*train_len):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20fdfc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_texts = [train_texts[i] for i in val_idx]\n",
    "val_cat = train_cat[val_idx]\n",
    "val_label = train_label[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8542a28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = [train_texts[i] for i in train_idx]\n",
    "train_cat = train_cat[train_idx]\n",
    "train_label = train_label[train_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a03aa42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6884, 3238)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_cat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee157e92",
   "metadata": {},
   "source": [
    "### Creating PyTorch Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1ef3b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b54cc307",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    def __init__(self, min_df):\n",
    "        self.itos = {0: '<pad>', 1: '<unk>'}\n",
    "        self.stoi = {'<pad>': 0, '<unk>': 1}\n",
    "        self.min_df = min_df\n",
    "        self.tokenizer = hazm.WordTokenizer(\n",
    "            join_verb_parts=False,\n",
    "            separate_emoji=True,\n",
    "            replace_links=True,\n",
    "            replace_IDs=False,\n",
    "            replace_emails=True,\n",
    "            replace_numbers=False,\n",
    "            replace_hashtags=False\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.itos)\n",
    "\n",
    "    def build_vocabulary(self, sentence_list):\n",
    "        frequencies = {}\n",
    "        idx = 2\n",
    "\n",
    "        for sentence in sentence_list:\n",
    "            for word in self.tokenizer.tokenize(sentence):\n",
    "                if word not in frequencies:\n",
    "                    frequencies[word] = 1\n",
    "                else:\n",
    "                    frequencies[word] += 1\n",
    "\n",
    "                if frequencies[word] == self.min_df:\n",
    "                    self.stoi[word] = idx\n",
    "                    self.itos[idx] = word\n",
    "                    idx += 1\n",
    "\n",
    "    def numericalize(self, text):\n",
    "        tokenized_text = self.tokenizer.tokenize(text)\n",
    "        \n",
    "        return [\n",
    "            self.stoi[token] if token in self.stoi else self.stoi['<unk>']\n",
    "            for token in tokenized_text\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "765b26e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigikalaDataset(Dataset):\n",
    "    def __init__(self, cat_mat, text_list, labels, vocab):\n",
    "        self.cat_mat = cat_mat\n",
    "        self.labels = labels\n",
    "        self.vocab = vocab\n",
    "            \n",
    "        self.text_list = [self.vocab.numericalize(text) for text in text_list]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        cat_row = self.cat_mat[index]\n",
    "        numer_text = self.text_list[index]\n",
    "        label = self.labels[index]\n",
    "        return T.tensor(cat_row, dtype=T.float32), T.tensor(numer_text, dtype=T.long), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82dad56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Collate:\n",
    "    def __init__(self, pad_idx):\n",
    "        self.pad_idx = pad_idx\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        cat_rows = [item[0] for item in batch]\n",
    "        cat_rows = T.vstack(cat_rows)\n",
    "        numer_texts = [item[1] for item in batch]\n",
    "        text_lengths = [text.shape[0] for text in numer_texts]\n",
    "        numer_texts = pad_sequence(numer_texts, batch_first=True, padding_value=self.pad_idx)\n",
    "        labels = [item[2] for item in batch]\n",
    "        labels = T.tensor(labels, dtype=T.float32)\n",
    "        \n",
    "        return cat_rows, numer_texts, labels, text_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66b7c486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loader(cat_mat, text_list, labels, vocab, batch_size=32, shuffle=True):\n",
    "    \n",
    "    dataset = DigikalaDataset(cat_mat, text_list, labels, vocab)\n",
    "    \n",
    "    pad_idx = dataset.vocab.stoi['<pad>']\n",
    "\n",
    "    loader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        collate_fn=Collate(pad_idx=pad_idx)\n",
    "    )\n",
    "\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128a1f5b",
   "metadata": {},
   "source": [
    "### Creating Loader Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe108655",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hazm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "282102fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_df=25\n",
    "vocab = Vocabulary(min_df)\n",
    "vocab.build_vocabulary(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e04b77c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1866"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "046594e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_loader(train_cat, train_texts, train_label, vocab, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66ba9ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = get_loader(val_cat, val_texts, val_label, vocab, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76597bcb",
   "metadata": {},
   "source": [
    "### Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0752ccf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2d4568f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regressor(nn.Module):\n",
    "    def __init__(self, cat_dim, dict_dim, embedding_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(dict_dim, embedding_dim, padding_idx=0, dtype=T.float32)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, num_layers=2, bidirectional=True, batch_first=True)\n",
    "\n",
    "        self.cat_shrink = nn.Sequential(\n",
    "            nn.Linear(cat_dim, 500),\n",
    "            nn.Tanh(),            \n",
    "        )\n",
    "                \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(1000, 200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, cat, text, text_lengths):\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "                        \n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(\n",
    "            embedded, text_lengths, enforce_sorted=False, batch_first=True)\n",
    "        \n",
    "        packed_output, hidden = self.gru(packed_embedded)\n",
    "                \n",
    "        hidden = T.cat((hidden[-2], hidden[-1]), dim=1)\n",
    "        \n",
    "        cat_shrinked = self.cat_shrink(cat)\n",
    "        \n",
    "        lin_input = T.cat((cat_shrinked, hidden), dim=1)\n",
    "        \n",
    "        out = self.fc(lin_input)\n",
    "        \n",
    "        out = 2 * out - 0.5\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "887f36b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CAT_DIM = train_cat.shape[1]\n",
    "DICT_DIM = vocab.__len__()\n",
    "EMBEDDING_DIM = 200\n",
    "HIDDEN_DIM = 250\n",
    "\n",
    "model = Regressor(CAT_DIM, DICT_DIM, EMBEDDING_DIM, HIDDEN_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c483c6",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bbc501c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "192fc49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9874e65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "criterion = criterion.to(device)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "26e5d8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(preds, y):\n",
    "    return mean_absolute_percentage_error(y, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5af4971f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    preds = []\n",
    "    labels = []\n",
    "    \n",
    "    model.train()\n",
    "        \n",
    "    for i, (cat, text, label, text_lengths) in enumerate(iterator):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        cat = cat.to(device)\n",
    "        text = text.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        predictions = model(cat, text, text_lengths).squeeze()\n",
    "        loss = criterion(predictions, label)\n",
    "                \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        preds += predictions.tolist()\n",
    "        labels += label.tolist()\n",
    "        \n",
    "        epoch_loss += loss.item() * len(text)\n",
    "        \n",
    "    epoch_score = score(preds, labels)\n",
    "                \n",
    "    return epoch_loss / len(iterator.dataset), epoch_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "520dabf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    preds = []\n",
    "    labels = []\n",
    "    \n",
    "    model.eval()\n",
    "        \n",
    "    for i, (cat, text, label, text_lengths) in enumerate(iterator):\n",
    "                \n",
    "        cat = cat.to(device)\n",
    "        text = text.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        predictions = model(cat, text, text_lengths).squeeze()\n",
    "        loss = criterion(predictions, label)\n",
    "                \n",
    "        preds += predictions.tolist()\n",
    "        labels += label.tolist()\n",
    "        \n",
    "        epoch_loss += loss.item() * len(text)\n",
    "        \n",
    "    epoch_score = score(preds, labels)\n",
    "                \n",
    "    return epoch_loss / len(iterator.dataset), epoch_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf4c78c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5a3f36",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Epoch Time: 0m 26s\n",
      "    Train Loss: 0.79362 | Train Score: 2035.72\n",
      "     Val. Loss: 0.96397 |  Val. Score: 2377.83\n",
      "\n",
      "Epoch: 2\n",
      "Epoch Time: 0m 26s\n",
      "    Train Loss: 0.74519 | Train Score: 1790.26\n",
      "     Val. Loss: 0.95377 |  Val. Score: 1799.79\n",
      "\n",
      "Epoch: 3\n",
      "Epoch Time: 0m 27s\n",
      "    Train Loss: 0.73931 | Train Score: 1780.85\n",
      "     Val. Loss: 0.95352 |  Val. Score: 1953.35\n",
      "\n",
      "Epoch: 4\n",
      "Epoch Time: 0m 28s\n",
      "    Train Loss: 0.73907 | Train Score: 1748.82\n",
      "     Val. Loss: 0.96189 |  Val. Score: 2237.20\n",
      "\n",
      "Epoch: 5\n",
      "Epoch Time: 0m 28s\n",
      "    Train Loss: 0.73774 | Train Score: 1713.09\n",
      "     Val. Loss: 0.95304 |  Val. Score: 2016.89\n",
      "\n",
      "Epoch: 6\n",
      "Epoch Time: 0m 28s\n",
      "    Train Loss: 0.73475 | Train Score: 1604.86\n",
      "     Val. Loss: 0.95173 |  Val. Score: 2153.64\n",
      "\n",
      "Epoch: 7\n",
      "Epoch Time: 0m 28s\n",
      "    Train Loss: 0.73501 | Train Score: 1607.17\n",
      "     Val. Loss: 0.95317 |  Val. Score: 2123.40\n",
      "\n",
      "Epoch: 8\n",
      "Epoch Time: 0m 27s\n",
      "    Train Loss: 0.73265 | Train Score: 1588.78\n",
      "     Val. Loss: 0.95146 |  Val. Score: 2113.34\n",
      "\n",
      "Epoch: 9\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 12\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    print(f'Epoch: {epoch+1}')\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_score = train(model, train_loader, optimizer, criterion)\n",
    "    valid_loss, valid_score = evaluate(model, val_loader, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    print(f'Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'    Train Loss: {train_loss:.5f} | Train Score: {train_score/10e8:.2f}')\n",
    "    print(f'     Val. Loss: {valid_loss:.5f} |  Val. Score: {valid_score/10e8:.2f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5505a128",
   "metadata": {},
   "source": [
    "### Saving The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "79844021",
   "metadata": {},
   "outputs": [],
   "source": [
    "T.save(model.state_dict(), 'model.torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ac9f1307",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vocab_stoi.pkl', 'wb') as f:\n",
    "    pickle.dump(vocab.stoi, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fcebda97",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vocab_itos.pkl', 'wb') as f:\n",
    "    pickle.dump(vocab.itos, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "dd924e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2770000000"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044f5130",
   "metadata": {},
   "source": [
    "### Loading The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ef5abc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import hazm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e61b0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vocab_stoi.pkl', 'rb') as f:\n",
    "    vocab_stoi = pickle.load(f)\n",
    "\n",
    "with open('vocab_itos.pkl', 'rb') as f:\n",
    "    vocab_itos = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91882b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocabulary(10)\n",
    "vocab.stoi = vocab_stoi\n",
    "vocab.itos = vocab_itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "581d6e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "CAT_DIM = 23123\n",
    "DICT_DIM = vocab.__len__()\n",
    "EMBEDDING_DIM = 200\n",
    "HIDDEN_DIM = 200\n",
    "\n",
    "model = Regressor(CAT_DIM, DICT_DIM, EMBEDDING_DIM, HIDDEN_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea928c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(T.load('model.torch'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe5eab41",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf4f775",
   "metadata": {},
   "source": [
    "### Loading Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4401346d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import load_npz\n",
    "import hazm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "62da3a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_texts.pkl', 'rb') as f:\n",
    "    test_texts = pickle.load(f)\n",
    "    \n",
    "test_cat = load_npz(\"test_cat.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e9c2a4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cat = test_cat.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "39e011cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = get_loader(test_cat, test_texts, np.zeros(len(test_texts)), vocab, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "550bab5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_label = 2770000000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bc3df4",
   "metadata": {},
   "source": [
    "### Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9330d25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, iterator):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    preds = []\n",
    "    \n",
    "    with T.no_grad():\n",
    "        for i, (cat, text, label, text_lengths) in enumerate(iterator):\n",
    "\n",
    "            cat = cat.to(device)\n",
    "            text = text.to(device)\n",
    "            \n",
    "            predictions = model(cat, text, text_lengths).squeeze()\n",
    "            preds += predictions.tolist()\n",
    "        \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9211936",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predict(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a83a8111",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [int(p * max_label) for p in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "565062d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [p if p > 0 else 0 for p in preds]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879a2fa0",
   "metadata": {},
   "source": [
    "### Saving to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9527e0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "017789e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0bfc1814",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame()\n",
    "pred_df['id'] = test_df['id']\n",
    "pred_df['price'] = avg_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a3b00a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>17517130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>17517130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8869557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17517130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>17517130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>17517130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>17517130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>17517130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>17517130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>17517130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>17517130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>17517130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>17517130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>17517130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>17517130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>17517130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>17517130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>17517130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>17517130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>17517130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>17517130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>17517130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>17517130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>17517130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>17517130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>17517130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>17517130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>17517130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>17517130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>17517130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>16235132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>11174421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>7625285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>7625285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>11670520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>11670520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>11174421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>11174421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>3414492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>9054144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>24810597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>43428936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>11174421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>5257847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>9718774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>10096492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>10187589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>10187589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>10187589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>7625285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id     price\n",
       "0    0  17517130\n",
       "1    1  17517130\n",
       "2    2   8869557\n",
       "3    3  17517130\n",
       "4    4  17517130\n",
       "5    5  17517130\n",
       "6    6  17517130\n",
       "7    7  17517130\n",
       "8    8  17517130\n",
       "9    9  17517130\n",
       "10  10  17517130\n",
       "11  11  17517130\n",
       "12  12  17517130\n",
       "13  13  17517130\n",
       "14  14  17517130\n",
       "15  15  17517130\n",
       "16  16  17517130\n",
       "17  17  17517130\n",
       "18  18  17517130\n",
       "19  19  17517130\n",
       "20  20  17517130\n",
       "21  21  17517130\n",
       "22  22  17517130\n",
       "23  23  17517130\n",
       "24  24  17517130\n",
       "25  25  17517130\n",
       "26  26  17517130\n",
       "27  27  17517130\n",
       "28  28  17517130\n",
       "29  29  17517130\n",
       "30  30  16235132\n",
       "31  31  11174421\n",
       "32  32   7625285\n",
       "33  33   7625285\n",
       "34  34  11670520\n",
       "35  35  11670520\n",
       "36  36  11174421\n",
       "37  37  11174421\n",
       "38  38   3414492\n",
       "39  39   9054144\n",
       "40  40  24810597\n",
       "41  41  43428936\n",
       "42  42  11174421\n",
       "43  43   5257847\n",
       "44  44   9718774\n",
       "45  45  10096492\n",
       "46  46  10187589\n",
       "47  47  10187589\n",
       "48  48  10187589\n",
       "49  49   7625285"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "dbf7b04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv('output.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.9.4",
   "language": "python",
   "name": "3.9.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
