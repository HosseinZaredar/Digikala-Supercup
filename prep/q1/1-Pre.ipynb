{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a43d25c8",
   "metadata": {},
   "source": [
    "### Loading The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "19741d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "013eb14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a609def1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caf41ed",
   "metadata": {},
   "source": [
    "### Unwrap Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "259fc226",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6ea0270e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unwrap_dict(dataframe):\n",
    "    product_df = pd.json_normalize(dataframe.product_description.apply(ast.literal_eval))\n",
    "    dataframe = pd.concat([product_df, dataframe], axis=1)\n",
    "    dataframe = dataframe.drop('product_description', axis=1)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fdc67221",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = unwrap_dict(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0471e400",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = unwrap_dict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "405f3a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in list(train_df.columns):\n",
    "    train_df[col] = train_df[col].apply(lambda x: x[0] if type(x) == list else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e606915d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in list(test_df.columns):\n",
    "    test_df[col] = test_df[col].apply(lambda x: x[0] if type(x) == list else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c720a72",
   "metadata": {},
   "source": [
    "### Removing Columns with >99% Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c109d538",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = len(train_df) * 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "38fa0781",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.dropna(thresh=limit, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f23017c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns = train_df.columns.values.tolist()\n",
    "columns.remove('price')\n",
    "columns.remove('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6b6cea13",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6eab42",
   "metadata": {},
   "source": [
    "### Analysing The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "0815a2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "fd3c1e25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8bb7ef091c5497b9a06390fd6518702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d523645c6d0e49908807328b4e5fa247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06edf7c2c2ce48bd91253a2a20a0f124",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc075bcb773942a8b56135d72b411b37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "profile = ProfileReport(train_df, title=\"Pandas Profiling Report\", minimal=True)\n",
    "profile.to_file(\"dataset_profile.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d815c0",
   "metadata": {},
   "source": [
    "### Creating Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "46ec4c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train_df[['price']].to_numpy().squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72887f75",
   "metadata": {},
   "source": [
    "### Categorical to One-Hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f061d717",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9b7c0cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_onehot(dataframe):\n",
    "    enc = OneHotEncoder(handle_unknown='ignore')\n",
    "    enc.fit(dataframe)\n",
    "    return enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "52cd2751",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = ['درگاه‌های ارتباطی', 'جنس بدنه' , 'جنس', 'اتصالات', 'سیستم عامل',\n",
    "               'نوع اتصال', 'رابط‌ها', 'اندازه', 'فناوری‌های ارتباطی',\n",
    "               'جنس کالا', 'دسته بندی', 'برند', 'نوع حافظه', 'سری پردازنده']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d9d09f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_model = train_onehot(train_df[cat_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a8c99537",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cat = onehot_model.transform(train_df[cat_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "322eb835",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cat = onehot_model.transform(test_df[cat_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7303de2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68840, 3238)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f9328f",
   "metadata": {},
   "source": [
    "### Categorical to Numeral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "329ce5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85cb237f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_numeral(dataframe, columns):\n",
    "    models = []\n",
    "    \n",
    "    for col in cat_columns:\n",
    "        enc = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=np.nan)\n",
    "        enc.fit(dataframe[[col]])\n",
    "        models.append(enc)\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1fe8502b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_numeral(dataframe, columns, models):\n",
    "    \n",
    "    classes = []\n",
    "    for i, col in enumerate(cat_columns):\n",
    "        cls = numeral_models[i].transform(train_df[[col]]).squeeze()\n",
    "        cls = np.nan_to_num(cls, nan=len(models[i].categories_[0]))\n",
    "        classes.append(cls)\n",
    "    \n",
    "    return np.vstack(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "342912e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = ['درگاه‌های ارتباطی', 'جنس بدنه', 'نوع رابط', 'قابلیت‌های دستگاه', 'جنس', 'اتصالات', 'سیستم عامل',\n",
    "               'نوع اتصال', 'رابط‌ها', 'ظرفیت', 'اندازه', 'فناوری‌های ارتباطی', 'جنس بند',\n",
    "               'جنس کالا', 'تعداد باتری‌های موجود در پک', 'قابلیت‌های باتری']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "73f769fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeral_models = train_numeral(train_df, cat_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "2cf1b13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cat = apply_numeral(train_df, cat_columns, numeral_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2609fc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cat = train_cat.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "eb247d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cat = apply_numeral(test_df, cat_columns, numeral_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e10a33db",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cat = test_cat.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d80861f",
   "metadata": {},
   "source": [
    "### Cleaning Text Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "32c1df18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hazm\n",
    "from hazm import Normalizer, WordTokenizer\n",
    "import re\n",
    "import pickle\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7c4f018b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('translation_dict.pickle', 'rb') as handle:\n",
    "    new_translation = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "878a60f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextHandler:\n",
    "    def __init__(self, persian_numbers=False,\n",
    "                 change_lang_spacing=True,\n",
    "                 remove_non_standard_char=True,\n",
    "                 remove_repetitive_chars=True,\n",
    "                 user_translations=None,\n",
    "                 stopwords=None,\n",
    "                 lemma=False\n",
    "                ):\n",
    "        \n",
    "        if not persian_numbers:\n",
    "            number_src = '۰۱۲۳۴۵۶۷۸۹٪'\n",
    "            number_dest = '0123456789%'\n",
    "        else:\n",
    "            number_dest = '۰۱۲۳۴۵۶۷۸۹٪'\n",
    "            number_src = '0123456789%'\n",
    "        \n",
    "        self.number_translations = self.maketrans(number_src, number_dest)\n",
    "        \n",
    "        if not user_translations:\n",
    "            self.user_translations = dict()\n",
    "        else:\n",
    "            self.user_translations = user_translations\n",
    "\n",
    "        self._remove_repetitive_chars = remove_repetitive_chars\n",
    "        self._change_lang_spacing = change_lang_spacing\n",
    "        self._remove_non_standard_char = remove_non_standard_char\n",
    "        self._stopwords = stopwords\n",
    "        \n",
    "        self.text_normalizer = hazm.Normalizer(\n",
    "            remove_extra_spaces=True,\n",
    "            persian_style=False,\n",
    "            persian_numbers=False,\n",
    "            remove_diacritics=True,\n",
    "            affix_spacing=True,\n",
    "            token_based=False,\n",
    "            punctuation_spacing=True)\n",
    "\n",
    "        self.word_tokenizer = hazm.WordTokenizer(\n",
    "            join_verb_parts=False,\n",
    "            separate_emoji=True,\n",
    "            replace_links=True,\n",
    "            replace_IDs=False,\n",
    "            replace_emails=True,\n",
    "            replace_numbers=False,\n",
    "            replace_hashtags=False)\n",
    "\n",
    "    def normalize(self, text: str):\n",
    "        text = text.translate(self.user_translations)\n",
    "        text = text.translate(self.number_translations)\n",
    "        \n",
    "        text = text.lower()\n",
    "\n",
    "        normalized_text = self.text_normalizer.normalize(text)\n",
    "\n",
    "        if self._remove_repetitive_chars:\n",
    "            text = self.remove_rep_chars(text)\n",
    "\n",
    "        if self._change_lang_spacing:\n",
    "            text = self.change_lang_spacing(text)\n",
    "\n",
    "        if self._remove_non_standard_char:\n",
    "            text = self.remove_non_standard_char(text)\n",
    "        \n",
    "        text = re.sub(r'[\\u200c\\s]*\\s[\\s\\u200c]*', ' ', text)\n",
    "        text = re.sub(r'[\\u200c]+', '\\u200c', text)\n",
    "\n",
    "        return text\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def maketrans(src_chars, dest_chars):\n",
    "        return dict((ord(a), b) for a, b in zip(src_chars, dest_chars))\n",
    "    \n",
    "    @staticmethod\n",
    "    def change_lang_spacing(text: str) -> str:\n",
    "        return re.sub('(([a-zA-Z0-9/\\-\\.]+)|([ء-یژپچگ]+))', r' \\1 ', text).strip()\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_non_standard_char(text: str) -> str:\n",
    "        return re.sub(r'[^a-zA-Z0-9\\u0621-\\u06CC\\u0698\\u067E\\u0686\\u06AF]', ' ', text)\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_rep_chars(text: str) -> str:\n",
    "        return re.sub(r'([^0-9])\\1\\1+', r'\\1', text)\n",
    "    \n",
    "    def preprocess_text(self, text: str):\n",
    "        normalized_text = self.normalize(text)\n",
    "        return normalized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fde4c7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_handler = TextHandler(user_translations=new_translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c10a43ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['توضیحات'] = train_df['توضیحات'].fillna('')\n",
    "train_df['سایر توضیحات'] = train_df['سایر توضیحات'].fillna('')\n",
    "train_df['سایر مشخصات'] = train_df['سایر مشخصات'].fillna('')\n",
    "train_df['مشخصات فنی'] = train_df['مشخصات فنی'].fillna('')\n",
    "train_df['وزن'] = train_df['وزن'].fillna('')\n",
    "train_df['ویژگی‌ها'] = train_df['ویژگی‌ها'].fillna('')\n",
    "\n",
    "\n",
    "train_df['text'] = ('<start> ' + train_df['توضیحات'] + ' <and> ' + train_df['سایر توضیحات'] +  ' <and> ' +\n",
    "               train_df['وزن'] + ' <and> ' + train_df['سایر مشخصات'] + ' <and> ' + train_df['مشخصات فنی'] +\n",
    "               ' <and> ' + train_df['ویژگی‌ها'] + ' <end>')\n",
    "\n",
    "\n",
    "train_df['text'] = train_df['text'].apply(text_handler.preprocess_text)\n",
    "train_texts = train_df['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7f0157de",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['توضیحات'] = test_df['توضیحات'].fillna('')\n",
    "test_df['سایر توضیحات'] = test_df['سایر توضیحات'].fillna('')\n",
    "test_df['سایر مشخصات'] = test_df['سایر مشخصات'].fillna('')\n",
    "test_df['مشخصات فنی'] = test_df['مشخصات فنی'].fillna('')\n",
    "test_df['وزن'] = test_df['وزن'].fillna('')\n",
    "test_df['ویژگی‌ها'] = test_df['ویژگی‌ها'].fillna('')\n",
    "\n",
    "test_df['text'] = ('<start> ' + test_df['توضیحات'] + ' <and> ' + test_df['سایر توضیحات'] +  ' <and> ' +\n",
    "               test_df['وزن'] + ' <and> ' + test_df['سایر مشخصات'] + ' <and> ' + test_df['مشخصات فنی'] +\n",
    "               ' <and> ' + test_df['ویژگی‌ها'] + ' <end>')\n",
    "\n",
    "test_df['text'] = test_df['text'].apply(text_handler.preprocess_text)\n",
    "test_texts = test_df['text'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf9714e",
   "metadata": {},
   "source": [
    "### Saving to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "dab38608",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from scipy.sparse import save_npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5f7a8f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_texts.pkl', 'wb') as f:\n",
    "    pickle.dump(train_texts, f)\n",
    "    \n",
    "save_npz(\"train_cat.npz\", train_cat)\n",
    "\n",
    "with open('train_label.npy', 'wb') as f:\n",
    "    np.save(f, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9576384a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_texts.pkl', 'wb') as f:\n",
    "    pickle.dump(test_texts, f)\n",
    "    \n",
    "save_npz(\"test_cat.npz\", test_cat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.9.4",
   "language": "python",
   "name": "3.9.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
